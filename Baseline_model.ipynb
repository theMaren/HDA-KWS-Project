{"cells":[{"cell_type":"code","execution_count":20,"id":"2eb8ce85","metadata":{"id":"2eb8ce85","outputId":"483d7a4b-55d1-4ec1-b477-5f9fc49cf98f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706945965194,"user_tz":-60,"elapsed":1764,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd 'drive/MyDrive/Uni/UniPD/HumanDataProject/Code'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEqy1dXmcxvS","executionInfo":{"status":"ok","timestamp":1706945965194,"user_tz":-60,"elapsed":7,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}},"outputId":"38771aa7-48f6-4903-857f-6571ff554b04"},"id":"OEqy1dXmcxvS","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Uni/UniPD/HumanDataProject/Code'\n","/content/drive/MyDrive/Uni/UniPD/HumanDataProject/Code\n"]}]},{"cell_type":"code","source":["import sys\n","import pandas as pd\n","import os\n","import numpy as np\n","from config import PREPROCESSING_PATH,DATASET_SPLIT_PATH\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from scipy.io import wavfile\n","\n","\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"id":"Dnh_q2hZctEa","executionInfo":{"status":"ok","timestamp":1706945965195,"user_tz":-60,"elapsed":6,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"id":"Dnh_q2hZctEa","execution_count":22,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow-io"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kD_dvG54gLOW","executionInfo":{"status":"ok","timestamp":1706945971329,"user_tz":-60,"elapsed":6140,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}},"outputId":"fcfea24a-561e-472e-84d0-4a0d0404d428"},"id":"kD_dvG54gLOW","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.10/dist-packages (0.35.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.35.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.35.0)\n"]}]},{"cell_type":"code","execution_count":24,"id":"4f7c5b6e","metadata":{"id":"4f7c5b6e","executionInfo":{"status":"ok","timestamp":1706945971329,"user_tz":-60,"elapsed":9,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["sys.path.append(\"drive/MyDrive/Uni/UniPD/HumanDataProject/Code\")"]},{"cell_type":"code","execution_count":25,"id":"88921d85","metadata":{"id":"88921d85","executionInfo":{"status":"ok","timestamp":1706945971329,"user_tz":-60,"elapsed":8,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["import preprocessing_tf"]},{"cell_type":"code","source":["print(\"GPU Available:\", tf.test.is_gpu_available())\n","print(\"Version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVNk6v9pF0vg","executionInfo":{"status":"ok","timestamp":1706945971329,"user_tz":-60,"elapsed":8,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}},"outputId":"ce30871e-0ca8-4aae-d102-a7d25acd2207"},"id":"BVNk6v9pF0vg","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available: False\n","Version: 2.15.0\n"]}]},{"cell_type":"markdown","id":"d11c6acc","metadata":{"id":"d11c6acc"},"source":["# Create train and validation dataset\n","\n","Construct dataframes that includes the file paths and the corresponding spoken command (label) for each audio sample. The dataset comprises audio samples of 25 keywords: `backward`, `down`, `eight`, `five`, `follow`, `forward`, `four`, `go`, `learn`, `left`, `nine`, `no`, `off`, `on`, `one`, `right`, `seven`, `six`, `stop`, `three`, `two`, `up`, `visual`, `yes`, `zero`. Additionally, it contains 10 words `bed`,`bird`,`cat`, `dog`,`happy`,`house`,`marvin`,`sheila`,`tree`,`wow` that the model should not recognize as keywords.\n","\n","To facilitate model training and evaluation, the labels are appropriately mapped: labels corresponding to the 25 keywords are retained in their original form, signifying that these are the commands the model is expected to recognize. Conversely, the labels for the 10 non-keyword words are mapped to a single class named \"unknown\". This approach consolidates these distinct non-keyword labels into a single category, simplifying the model's task by reducing the classification scope to the keywords and an \"unknown\" class for any non-keyword utterances."]},{"cell_type":"code","execution_count":27,"id":"56f85477","metadata":{"id":"56f85477","executionInfo":{"status":"ok","timestamp":1706945974164,"user_tz":-60,"elapsed":2842,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["train_df = preprocessing_tf.get_file_list(os.path.join(DATASET_SPLIT_PATH,\"train\"))\n","val_df = preprocessing_tf.get_file_list(os.path.join(DATASET_SPLIT_PATH,\"validation\"))"]},{"cell_type":"code","execution_count":28,"id":"46559deb","metadata":{"id":"46559deb","outputId":"75a4b34e-4bdf-4381-ad7c-b9112afdd453","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1706945974165,"user_tz":-60,"elapsed":11,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            filepath     label mapped_label\n","0  /content/drive/MyDrive/Uni/UniPD/HumanDataProj...  backward     backward\n","1  /content/drive/MyDrive/Uni/UniPD/HumanDataProj...  backward     backward\n","2  /content/drive/MyDrive/Uni/UniPD/HumanDataProj...  backward     backward\n","3  /content/drive/MyDrive/Uni/UniPD/HumanDataProj...  backward     backward\n","4  /content/drive/MyDrive/Uni/UniPD/HumanDataProj...  backward     backward"],"text/html":["\n","  <div id=\"df-bc733751-fc93-4239-b481-8ea87122610e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepath</th>\n","      <th>label</th>\n","      <th>mapped_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/Uni/UniPD/HumanDataProj...</td>\n","      <td>backward</td>\n","      <td>backward</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/Uni/UniPD/HumanDataProj...</td>\n","      <td>backward</td>\n","      <td>backward</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/Uni/UniPD/HumanDataProj...</td>\n","      <td>backward</td>\n","      <td>backward</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/Uni/UniPD/HumanDataProj...</td>\n","      <td>backward</td>\n","      <td>backward</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/Uni/UniPD/HumanDataProj...</td>\n","      <td>backward</td>\n","      <td>backward</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc733751-fc93-4239-b481-8ea87122610e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bc733751-fc93-4239-b481-8ea87122610e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bc733751-fc93-4239-b481-8ea87122610e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-74ba41fe-d90f-4317-96db-d0516ffe14eb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74ba41fe-d90f-4317-96db-d0516ffe14eb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-74ba41fe-d90f-4317-96db-d0516ffe14eb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":28}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":29,"id":"a194e041","metadata":{"id":"a194e041","executionInfo":{"status":"ok","timestamp":1706945974165,"user_tz":-60,"elapsed":8,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["file_paths = tf.constant(train_df['filepath'].values)\n","labels = tf.constant(train_df['mapped_label'].values)"]},{"cell_type":"code","execution_count":30,"id":"cb09165f","metadata":{"id":"cb09165f","executionInfo":{"status":"ok","timestamp":1706945980273,"user_tz":-60,"elapsed":6116,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["# Create a StringLookup layer\n","#label_lookup = label_lookup = tf.keras.layers.StringLookup(num_oov_indices=0)\n","label_lookup = tf.keras.layers.StringLookup()\n","label_lookup.adapt(labels)\n","# Transform labels into numeric\n","numeric_labels = label_lookup(labels)\n","\n","# Create a TensorFlow dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices((file_paths, numeric_labels))"]},{"cell_type":"code","execution_count":31,"id":"0a375ae5","metadata":{"id":"0a375ae5","executionInfo":{"status":"ok","timestamp":1706945980274,"user_tz":-60,"elapsed":8,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["file_paths_val = tf.constant(val_df['filepath'].values)\n","labels_val = tf.constant(val_df['mapped_label'].values)\n","numeric_labels_val = label_lookup(labels_val)\n","validation_dataset = tf.data.Dataset.from_tensor_slices((file_paths_val, numeric_labels_val))"]},{"cell_type":"markdown","id":"f7acedd9","metadata":{"id":"f7acedd9"},"source":["# Preprocessing the Datasets\n","\n","The training and validation datasets undergo preprocessing through our established pipeline. For the baseline model, the preprocessing involves two steps: padding the data to ensure uniformity in size, which is essential for the model's input requirements, and converting the audio files into spectrograms."]},{"cell_type":"code","execution_count":32,"id":"c8ed5a41","metadata":{"id":"c8ed5a41","outputId":"46cda47a-40ec-420c-d073-4643d48b6145","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706945980274,"user_tz":-60,"elapsed":7,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data shape: (None,)\n","Padding shape: (16000,)\n","Signal shape: (16000,)\n","Spectrogram shape: (124, 129, 1)\n","Final shape: (124, 129, 1)\n","Data shape: (None,)\n","Padding shape: (16000,)\n","Signal shape: (16000,)\n","Spectrogram shape: (124, 129, 1)\n","Final shape: (124, 129, 1)\n"]}],"source":["#With parameters\n","#train_spectrogram_ds = train_dataset.map(lambda fp, lbl: preprocessing_tf.preprocess_map_new(fp, lbl,resample=True,mfcc=True),\n","#                               num_parallel_calls=tf.data.AUTOTUNE)\n","\n","train_spectrogram_ds = train_dataset.map(lambda fp, lbl: preprocessing_tf.preprocess_map_new(fp, lbl),\n","                               num_parallel_calls=tf.data.AUTOTUNE)\n","train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n","\n","\n","val_spectrogram_ds = validation_dataset.map(lambda fp, lbl: preprocessing_tf.preprocess_map_new(fp, lbl),\n","                               num_parallel_calls=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":33,"id":"788b5695","metadata":{"id":"788b5695","executionInfo":{"status":"ok","timestamp":1706945980274,"user_tz":-60,"elapsed":6,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}}},"outputs":[],"source":["batch_size = 32\n","train_spectrogram_ds = train_spectrogram_ds.batch(batch_size)\n","val_spectrogram_ds = val_spectrogram_ds.batch(batch_size)"]},{"cell_type":"code","execution_count":34,"id":"9cdbc8d4","metadata":{"id":"9cdbc8d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706945980274,"user_tz":-60,"elapsed":6,"user":{"displayName":"Maren Hoschek","userId":"01922856652202682312"}},"outputId":"6e746924-0fe6-40b6-f3aa-d8b86805b0df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: (124, 129, 1)\n","Number of labels: 27\n"]}],"source":["input_shape =train_spectrogram_ds.element_spec[0].shape[1:]\n","print('Input shape:', input_shape)\n","num_labels = len(label_lookup.get_vocabulary())\n","print('Number of labels:', num_labels)"]},{"cell_type":"markdown","id":"244560d6","metadata":{"id":"244560d6"},"source":["# Model\n","\n","The baseline model adopted for our analysis originates from the TensorFlow tutorial designed for a mini version of the speech dataset https://www.tensorflow.org/tutorials/audio/simple_audio. This model serves primarily as a benchmark for comparison purposes. Our objective is to demonstrate that subsequent models, which incorporate more intricate architectures or employ additional preprocessing steps, will surpass the performance of this baseline model."]},{"cell_type":"code","execution_count":null,"id":"a8417c75","metadata":{"id":"a8417c75"},"outputs":[],"source":["# Instantiate the `tf.keras.layers.Normalization` layer.\n","norm_layer = layers.Normalization()\n","# Fit the state of the layer to the spectrograms\n","# with `Normalization.adapt`.\n","norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n","\n","model = models.Sequential([\n","    layers.Input(shape=input_shape),\n","    # Downsample the input.\n","    layers.Resizing(32, 32),\n","    # Normalize.\n","    norm_layer,\n","    layers.Conv2D(32, 3, activation='relu'),\n","    layers.Conv2D(64, 3, activation='relu'),\n","    layers.MaxPooling2D(),\n","    layers.Dropout(0.25),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_labels),\n","])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"db148b8f","metadata":{"id":"db148b8f"},"outputs":[],"source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'],\n","    run_eagerly=True  # Enable eager execution for debugging\n",")"]},{"cell_type":"code","execution_count":null,"id":"6c0669b0","metadata":{"id":"6c0669b0"},"outputs":[],"source":["EPOCHS = 8\n","history = model.fit(\n","    train_spectrogram_ds,\n","    validation_data=val_spectrogram_ds,\n","    epochs=EPOCHS,\n","    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",")"]},{"cell_type":"markdown","id":"34bc8e08","metadata":{"id":"34bc8e08"},"source":["# Evaluation\n","The model's performance on our test dataset is assessed using the top-1 error rate, which is the same metric employed by the dataset's creator."]},{"cell_type":"code","execution_count":null,"id":"9a0de4b6","metadata":{"id":"9a0de4b6"},"outputs":[],"source":["test_df = preprocessing_tf.get_file_list(os.path.join(DATASET_SPLIT_PATH,\"test\"))\n","file_paths_test = tf.constant(test_df['filepath'].values)\n","labels_test = tf.constant(test_df['mapped_label'].values)\n","numeric_labels_test = label_lookup(labels_test)\n","test_dataset = tf.data.Dataset.from_tensor_slices((file_paths_test, numeric_labels_test))\n"]},{"cell_type":"code","execution_count":null,"id":"1f83e554","metadata":{"id":"1f83e554"},"outputs":[],"source":["test_spectrogram_ds = test_dataset.map(lambda fp, lbl: preprocessing_tf.preprocess_map_new(fp, lbl),\n","                               num_parallel_calls=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"id":"315cd4c5","metadata":{"id":"315cd4c5"},"outputs":[],"source":["predictions = model.predict(test_spectrogram_ds)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","true_labels = np.concatenate([y for x, y in test_spectrogram_ds], axis=0)\n","accuracy = np.mean(predicted_classes == true_labels)\n","\n","print(f\"Manual Test Accuracy: {accuracy}\")\n","\n","# Calculate the Top-1 Error Rate\n","top_1_error_rate = 1 - accuracy\n","print(f\"Manual Top-1 Error Rate: {top_1_error_rate}\")"]},{"cell_type":"code","execution_count":null,"id":"032f15a3","metadata":{"id":"032f15a3"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}